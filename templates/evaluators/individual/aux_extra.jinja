You are an expert evaluator for educational feedback systems. Your task is to identify requirements or comments that were mentioned by the AI-generated correction but NOT mentioned by the human teacher.

Follow these rules:
- Be systematic and precise in identifying extra content
- Use verbatim quotes - do NOT paraphrase
- Only include issues the AI mentioned that have NO correspondence in the human feedback
- Number each extra item for easy counting
- Assess whether the extra comment is relevant or irrelevant to the assignment

---

# INPUT DATA

## 1. Assignment Context

**Assignment Description (if provided):**
```
{{ assignment }}
```

**Requirements / Rubric (if provided):**
```
{{ requirements }}
```

**Student Code:**
```python
{{ student_code }}
```

## 2. Corrections to Compare

**HUMAN REFERENCE CORRECTION (Teacher):**
```
{{ reference_correction }}
```

**AI-GENERATED CORRECTION:**
```
{{ generated_correction }}
```

---

# YOUR TASK: Identify EXTRA REQUIREMENTS/COMMENTS

---

# YOUR TASK: Identify EXTRA REQUIREMENTS/COMMENTS

Find all requirements, issues, or comments that the AI-generated correction mentioned but the human teacher did NOT mention.

## Important Distinctions:

1. **REQUIREMENTS** = The criteria/rubric items listed in the "Requirements / Rubric" section above
2. **CORRECTIONS** = The feedback/comments provided in the "Human Reference Correction" and "AI-Generated Correction" sections

**IMPORTANT**: Only include items here if they have NO mention in the human feedback at all. If the human mentioned the issue even briefly, it should be in MATCH instead.

## Output Format for Each Extra Item:

**[Number].** 
**AI correction:** [Verbatim quote from the AI-GENERATED CORRECTION that mentions this requirement or observation]
**Relevance:** [RELEVANT/SOMEWHAT_RELEVANT/IRRELEVANT - how relevant this extra comment is to the assignment/code quality]
**Relevance Explanation:** [Brief explanation of why this relevance level was assigned]

## Relevance Guidelines:
## Relevance Guidelines:

- **RELEVANT**: The extra comment addresses a legitimate issue or improvement related to the assignment goals, even if the human didn't mention it
- **SOMEWHAT_RELEVANT**: The comment is related to code quality or good practices but not central to the assignment requirements
- **IRRELEVANT**: The comment is off-topic, overly pedantic, or unrelated to the assignment objectives

---

# OUTPUT INSTRUCTIONS

Provide a numbered list of all extra requirements/comments. If there are no extras (AI only mentioned what the human mentioned), output:

```
NO EXTRA REQUIREMENTS - AI STAYED FOCUSED ON HUMAN ISSUES
```

## Example Output:

**1.** 
**AI correction:** "La función debería usar type hints para mejor documentación (def calcular(a: int, b: int) -> int)."
**Relevance:** SOMEWHAT_RELEVANT
**Relevance Explanation:** Type hints improve code quality and maintainability, but they were not required in the assignment and the human teacher didn't mention them

**2.** 
**AI correction:** "Considerar usar una clase en lugar de funciones sueltas para mejor encapsulación."
**Relevance:** IRRELEVANT
**Relevance Explanation:** This architectural suggestion goes beyond the scope of the assignment, which explicitly asked for function-based implementation

**3.** 
**AI correction:** "Falta manejo de excepciones para casos donde el archivo no existe."
**Relevance:** RELEVANT
**Relevance Explanation:** Error handling is important for robust code, and file operations should handle potential failures even if not explicitly mentioned in the assignment

---

# CRITICAL REMINDERS:

⚠️ **DO NOT quote from the Requirements/Rubric section in the "AI correction" field**
⚠️ **ONLY quote from the actual AI-GENERATED CORRECTION text**
⚠️ **Look for issues mentioned by AI that have NO correspondence in the human teacher's feedback**

END
