# Configuration for Assignment Evaluation System
# This system coordinates three specialized agents for automated code evaluation

# Global LLM Configuration (used as fallback if agent-specific config is not provided)
model_name: "deepseek-r1:14b"  # Default model for all agents
provider: "ollama"
temperature: 0.1

# RAG Configuration
enable_rag: false
rag_knowledge_base: null

# Agent Configuration
# Each agent can have its own model configuration
# If not specified, the agent will use the global configuration above
agents:
  requirement_generator:
    enabled: true
    # Agent-specific model configuration (optional)
    # Uncomment and modify these lines to use a different model for this agent
    model_name: "deepseek-r1:14b"  # Different model for requirement generation
    # provider: "openai"   # Different provider for requirement generation
    # temperature: 0.2     # Different temperature for requirement generation
    template: "requirement_generator.jinja"  # Jinja template for requirement generation
    
  prompt_generator:
    enabled: true
    include_examples: true
    include_resources: true
    # Agent-specific model configuration (optional)
    # Uncomment and modify these lines to use a different model for this agent
    # model_name: "qwen2.5:7b"  # Different model for prompt generation
    # provider: "ollama"        # Different provider for prompt generation
    # temperature: 0.15         # Different temperature for prompt generation
    templates:
      default: "prompt_generator_presence.jinja"
      presence: "prompt_generator_presence.jinja"
      conceptual: "prompt_generator_conceptual.jinja"
    
  code_corrector:
    enabled: true
    detailed_feedback: true
    include_suggestions: true
    include_learning_resources: true
    # Agent-specific model configuration (optional)
    # Uncomment and modify these lines to use a different model for this agent
    # model_name: "gpt-4-turbo"  # Different model for code correction
    # provider: "openai"         # Different provider for code correction
    # temperature: 0.05          # Different temperature for code correction

  # Agent Evaluator Configuration
  agent_evaluator:
    enabled: true
    # Agent-specific model configuration for the evaluator
    model_name: "deepseek-r1:14b"  # Model for evaluation (should be high quality)
    provider: "ollama"         # Provider for evaluation
    temperature: 0.1           # Low temperature for consistent evaluation
    evaluation_criteria:
      requirement_generator:
        - completeness
        - clarity
        - specificity
        - coherence
        - independence
      prompt_generator:
        - template_completeness
        - clarity
        - specificity
        - code_analysis_focus
        - jinja2_syntax
      code_corrector:
        - requirement_coverage
        - analysis_depth
        - clarity
        - accuracy
        - actionability

# Programming Language Support
languages:
  python:
    name: "Python"
    file_extensions: [".py"]
    syntax_highlighting: "python"
    
  javascript:
    name: "JavaScript"
    file_extensions: [".js", ".jsx"]
    syntax_highlighting: "javascript"
    
  java:
    name: "Java"
    file_extensions: [".java"]
    syntax_highlighting: "java"

  
# Logging Configuration
logging:
  level: "INFO"  # Options: "DEBUG", "INFO", "WARNING", "ERROR"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "assignment_evaluator.log"
